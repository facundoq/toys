{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib \n",
    "\n",
    "\n",
    "def is_covariance(x):\n",
    "    # checks if x is a valid covariance matrix (symmetric and pos-def)\n",
    "    symmetric= np.all(x==x.T)\n",
    "    pos_def=np.all(np.linalg.eigvals(x) > 0)\n",
    "    return symmetric and pos_def\n",
    "\n",
    "\n",
    "\n",
    "def plot_data(x,title,eigen=False):\n",
    "    # plot 3d data\n",
    "    # x must be of size (n,3)\n",
    "    # if eigen=True, also plot eigenvectors of cov(x), with the corresponding eigenvalue\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(x[:,0],x[:,1],zs=x[:,2],alpha=0.1)\n",
    "    limit_max=np.max(x)+1\n",
    "    limit_min=np.min(x)-1\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_zlabel(\"z\")\n",
    "    ax.set_xlim(limit_min, limit_max)\n",
    "    ax.set_ylim(limit_min, limit_max)\n",
    "    ax.set_zlim(limit_min, limit_max)\n",
    "    ax.set_title(title)\n",
    "    if eigen==True:\n",
    "        n,features=x.shape\n",
    "        mu=np.mean(x,axis=0)\n",
    "        pca = PCA(n_components=features)\n",
    "        pca.fit(x)\n",
    "        eigenvectors=pca.components_ # each row is an eigenvector\n",
    "        eigenvalues=pca.explained_variance_ # eigenvalues\n",
    "        \n",
    "        scale=np.abs(x).max()\n",
    "        #scaled_eigenvectors=eigenvectors/(eigenvalues+0.2)*scale\n",
    "        scaled_eigenvectors=eigenvectors*scale/4\n",
    "        ax.scatter([mu[0]],[mu[1]],zs=[mu[2]],color=\"green\",s=150)\n",
    "        endpoints=scaled_eigenvectors+mu\n",
    "        for i in range(features):\n",
    "            ax.plot([mu[0], endpoints[i,0]], [mu[1],endpoints[i,1]], [mu[2], endpoints[i,2]], color='red', alpha=0.8, lw=2)\n",
    "            ax.text(endpoints[i,0],endpoints[i,1],endpoints[i,2],  '$\\lambda_{%d}$=%0.2f' % (i,eigenvalues[i]), size=8, zorder=1)  \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data to simulate a dataset of samples $x$ in which all features/columns (3) could be collected. x has size $n$ by $features$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mean and std of multivariate normal dist to generate samples\n",
    "mu=np.array([5,0,-2])\n",
    "σ=np.array([[9,1, -1],\n",
    "            [1, 3, -2],\n",
    "            [-1, -2,2],])\n",
    "if not is_covariance(σ):\n",
    "    print(\"Warning: σ is not a valid covariance matrix (not symmetric or positive definite)\")\n",
    "\n",
    "n=1000 # number of samples\n",
    "x=np.random.multivariate_normal(mu,σ,size=(n,))\n",
    "\n",
    "#plot generated data\n",
    "plt.close(\"all\")\n",
    "plot_data(x,\"data in original space\",eigen=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the generated data $x$ to a new basis. \n",
    "The basis is given by the eigenvectors of $cov(x)$. In this new basis, the eigenvectors are the same as the $x$, $y$, $z$ axis vectors $(1,0,0)$, $(0,1,0)$, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca_exact = PCA(n_components=3) # since x has 3 features, this PCA model does not do compression\n",
    "pca_exact.fit(x) # calculate eigen decomposition of cov(x)\n",
    "\n",
    "x_transformed=pca_exact.transform(x) #encode x with the eigenvectors as basis\n",
    "plot_data(x_transformed,\"x in natural (eigenvectors) space\",eigen=True)\n",
    "\n",
    "#save the eigenvectors and eigenvalues\n",
    "eigenvectors=pca_exact.components_\n",
    "eigenvalues=pca_exact.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate another dataset $y$ with the same distribution as $x$ (this is a very strong assumption!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.random.multivariate_normal(mu,σ,size=(n,))\n",
    "plot_data(y,\"y in original space\",eigen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets simulate the fact that for $y$ we can't measure all values. In this case, we will create `y_missing`, which only has 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'y_missing in original space (2d)')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_missing=y[:,0:2]\n",
    "plt.figure()\n",
    "plt.scatter(y_missing[:,0],y_missing[:,1])\n",
    "plt.title(\"y_missing in original space (2d)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets assume that we can recover the last feature of `y_missing`  using information from the eigendecomposition of $cov(x)$. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We perform PCA on $x$, but use only the two most important eigenvectors (those with bigger eigenvalues). `pca_reconstruction` allows us to perform a forward transform from $R^3$ to $R^2$ (compression) and an inverse transform from $R^2$ to $R^3$ (reconstruction). This can also be interpreted as going from the canonical basis to the eigenbasis and viceversa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.94125744  0.25425767 -0.22223293]\n",
      " [ 0.33698043 -0.74984978  0.56935884]]\n",
      "[[ 0.94125744  0.25425767 -0.22223293]\n",
      " [ 0.33698043 -0.74984978  0.56935884]\n",
      " [-0.02187746 -0.61080139 -0.79148154]]\n"
     ]
    }
   ],
   "source": [
    "pca_reconstruction=PCA(n_components=2)\n",
    "pca_reconstruction.fit(x)\n",
    "print(pca_reconstruction.components_)\n",
    "print(eigenvectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still can't reconstruct `y` from `y_missing` with `pca_reconstruction` because it is encoded with the canonical basis. We first need to encode it in the eigenbasis. To do that we will augment `y_missing` with a new feature with value equal to the mean of that feature (a reasonable assumption), and encode it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_augmented=np.copy(y_missing)\n",
    "y3=np.zeros((n,1))+mu[2]\n",
    "y_augmented=np.hstack([y_missing,y3])\n",
    "y_eigen=pca_exact.transform(y_augmented)\n",
    "\n",
    "least_eigenvalue_index=np.argmin(eigenvalues)\n",
    "y_eigen_2d=y_eigen[:,np.arange(3)!=least_eigenvalue_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reconstructed=pca_reconstruction.inverse_transform(y_eigen_2d)\n",
    "plot_data(y_reconstructed, \"y_reconstructed\",eigen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1738605988\n"
     ]
    }
   ],
   "source": [
    "mean_reconstruction_error=((y_reconstructed-y)**2).sum()/n\n",
    "print(mean_reconstruction_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
